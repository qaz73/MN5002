{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qaz73/MN5002/blob/main/Section%201/Section1Assignment_gorourke.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bdMWHukOcnxL"
      },
      "source": [
        "# Section 1 Assignment - word vectors\n",
        "\n",
        "Student number : 24514772\n",
        "\n",
        "...This workbook follows the assignment templates in this order\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "ea-_hbaqr0sQ"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DiIM1DiJcnxM"
      },
      "source": [
        "The goals of the assignment include the following:\n",
        "* Checking your understanding of the basic operations and relationships between word vectors on a downloaded corpus using Gensim\n",
        "* Performing vector reasoning  on the corpus to determine answers to questions\n",
        "* Identifying and exploring deficiencies and biases in a corpus\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kd5sBgVZcnxM"
      },
      "source": [
        "## Download a pre-trained corpus\n",
        "Firstly ensure that you have Gensim installed and that it is the latest version. You will use Gensim to work with a corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tsMQcNk0cnxN",
        "outputId": "5a6d521d-8290-476d-82e5-f054f62eeda0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m47.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ],
      "source": [
        "%pip install --upgrade gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9DpG4sOKcnxN"
      },
      "source": [
        "Next, import Gensim"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "CSy7Xw0RriA5"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "import gensim.downloader"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrrYV3cHcnxN"
      },
      "source": [
        "Next set a download directory for your Gensim data. You will need to modify the path to the directory to your own needs. Some tips on this are given [here](https://radimrehurek.com/gensim/downloader.html#gensim.downloader.BASE_DIR)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "1EckFY2GcnxO"
      },
      "outputs": [],
      "source": [
        "import gensim.downloader as api\n",
        "#api.BASE_DIR = '/content/drive/MyDrive/MN5002'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0WWO9Hi3cnxO"
      },
      "source": [
        "Now, download the Google News corpus cited by Tomas Mikolov et.al. in [Distributed Representations of Words and Phrases and their Compositionality](http://arxiv.org/pdf/1310.4546.pdf). It is a big file, so it can take a few minutes.\n",
        "\n",
        "**NOTE:** Especially in colab, when the file is done downloading you can see this error: FileNotFoundError: [Errno 2] No such file or directory: '/root/gensim-data/word2vec-google-news-300/word2vec-google-news-300.gz'\n",
        "\n",
        "This is because the function is trying to also read the file (not just download it). In colab, it tries to read the file on a path that is different from the one we specified above. Double check the give location, you should still see that \"word2vec-google-news-300.gz\" was succesfully downloaded. If so, you can ignore the error and open the file as we did in \"gensim_word2vec_examples\".\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "b4n6p-gjcnxO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0d6b680-645a-43a1-ad2e-d5ae984c1997"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ls: cannot access '/content/drive/MyDrive/MN5002/word2vec-google-news-300': No such file or directory\n",
            "[==================================================] 100.0% 1662.8/1662.8MB downloaded\n"
          ]
        }
      ],
      "source": [
        "!ls /content/drive/MyDrive/MN5002/word2vec-google-news-300\n",
        "google_news_vectors = api.load('word2vec-google-news-300')\n",
        "#from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "# - https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.load_word2vec_format.html\n",
        "# binary is a boolean indicating whether the data is in binary word2vec format\n",
        "# limit sets a maximum number of word-vectors to read from the file. The default, None, means read all.\n",
        "#google_news_vectors = KeyedVectors.load_word2vec_format(\"/content/drive/MyDrive/MN5002/word2vec-google-news-300/word2vec-google-news-300.gz\", binary=True, limit=200000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdbyc5DqriA6"
      },
      "source": [
        "Now it is time to explore the word vectors. You need to write code that uses [Gensim's word vector representations](https://radimrehurek.com/gensim/models/keyedvectors.html#gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar) to answer the following questions and provide explanations of your answers using a Python print statement after each code step in your code, with careful consideration of how the meaning extracted from the corpus may be incorrect :\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def print_similarity_table(header, data) :\n",
        "    print('\\n' + header)\n",
        "    print('-' * 30)\n",
        "    for word, score in data :\n",
        "        print(f\"{word:30} {score}\")"
      ],
      "metadata": {
        "id": "VIy1-aC1Ucfk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q1. Knowing that the capital of Paris is France, use vector reasoning to find the capital of **Germany** and the capital of **Australia** and explain the answers"
      ],
      "metadata": {
        "id": "A0Z8fJDDFcTF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.most_similar.html\n",
        "# Paris - France ~ capital - country\n",
        "# Paris - France ~ captial - Germany\n",
        "# Paris + Germany - France ~ Capital\n",
        "germany_capital = google_news_vectors.most_similar(positive=['Paris', 'Germany'], negative=['France'], topn=3)\n",
        "\n",
        "australia_capital = google_news_vectors.most_similar(positive=['Paris', 'Australia'], negative=['France'], topn=5)\n",
        "\n",
        "germany_capital, australia_capital"
      ],
      "metadata": {
        "id": "E9440bJ6IVjy",
        "outputId": "4196698c-f671-4ccd-9e62-02fd7086f234",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "([('Berlin', 0.7644002437591553),\n",
              "  ('Frankfurt', 0.7329736351966858),\n",
              "  ('Dusseldorf', 0.7009457349777222)],\n",
              " [('Sydney', 0.7721031308174133),\n",
              "  ('Melbourne', 0.7192801833152771),\n",
              "  ('Canberra', 0.6764731407165527),\n",
              "  ('Brisbane', 0.6720366477966309),\n",
              "  ('Adelaide', 0.6661337614059448)])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q2.  By considering the **USA** and by considering **Russia**, use vector reasoning to find the UK Prime Minister from the corpus and explain the answers you get.\n",
        "\n",
        "Approach\n",
        "- Try and find out the equivalent role for USA / Russia.\n",
        "- If we cannot infer the role name, then we assume that the role name is President"
      ],
      "metadata": {
        "id": "FXfGyzfMFlZ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# v(UK) - v(Prime Minister) ~ v(USA) - v(US_Equivalent)\n",
        "# v(UK) - v(Prime Minister) - v(USA) ~  v(US_Equivalent)\n",
        "\n",
        "# List all words containing \"prime\"\n",
        "#res = [w for w in google_news_vectors.key_to_index if \"prime\" in w.lower()]\n",
        "#print (res)\n",
        "\n",
        "# Prime Minister is in the vectors as Prime_Minister and prime_minister - use the lower case one\n",
        "# Try and find Role name for USA & Russia equivalent of Prime Minister\n",
        "us_equivalent_of_uk_prime_minister = google_news_vectors.most_similar(positive=['prime_minister', 'USA'], negative=['UK'], topn=10)\n",
        "print_similarity_table('US Equivalent of Prime Minister', us_equivalent_of_uk_prime_minister)\n",
        "\n",
        "print('From the word embeddings, we were unable to determine the equivalent role in the USA for Prime Minister, using vector arithmetic.  We will have to use our own domain knowledge and use the role name as President.  This is likely due to corpus bias: the news having fewer articles linking the USA President with the  UK Prime Minister')\n",
        "\n",
        "russia_equivalent_of_uk_prime_minister = google_news_vectors.most_similar(positive=['prime_minister', 'Russia'], negative=['UK'], topn=10)\n",
        "print_similarity_table('Russia Equivalent of Prime Minister',russia_equivalent_of_uk_prime_minister)\n",
        "\n",
        "print('We are unable to find the equivalent of ')"
      ],
      "metadata": {
        "id": "Vbu3CXbeS1tZ",
        "outputId": "b3d0de8d-c7ad-4882-96f7-0a249e77fcd8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "US Equivalent of Prime Minister\n",
            "------------------------------\n",
            "prime_minster                  0.5071303844451904\n",
            "Prime_Minister                 0.4752308130264282\n",
            "Prime_Minsiter                 0.470718652009964\n",
            "prime_minsiter                 0.4681420922279358\n",
            "Prime_Minster                  0.46444687247276306\n",
            "prime_ministers                0.45180338621139526\n",
            "Prime_Mnister                  0.4313995838165283\n",
            "Inder_Kumar_Gujral             0.4286772310733795\n",
            "Prime_MInister                 0.4268903136253357\n",
            "Tsakhia_Elbegdorj              0.4198894798755646\n",
            "\n",
            "Russia Equivalent of Prime Minister\n",
            "------------------------------\n",
            "President_Vladimir_Putin       0.6197234988212585\n",
            "Putin                          0.6101216077804565\n",
            "prime_minister_Viktor_Zubkov   0.5979375839233398\n",
            "Vladimir_Putin                 0.5920553803443909\n",
            "Putin_handpicked_successor     0.5757296085357666\n",
            "Prime_Minister_Vladmir_Putin   0.5756816864013672\n",
            "Prime_Minister_Vladimir_Putin  0.5679253935813904\n",
            "Medvedev                       0.561940610408783\n",
            "Victor_Yuschenko               0.5601823925971985\n",
            "Prime_Minister_Yulia_Timoshenko 0.5547938942909241\n",
            "We are unable to find the equivalent of \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q3. What are the 5 most similar words to the word **BMW**? Explain your answer."
      ],
      "metadata": {
        "id": "wPZ1r6aNFo3M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similar_bmw = google_news_vectors.most_similar('BMW', topn=5)\n",
        "similar_bmw"
      ],
      "metadata": {
        "id": "br09zbHiaVRr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q4. What are the 5 most similar words to the word **Tesla**? Explain your answer.\n"
      ],
      "metadata": {
        "id": "AQaW4ra3Fsyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "similar_tesla = google_news_vectors.most_similar('Tesla', topn=5)\n",
        "similar_tesla"
      ],
      "metadata": {
        "id": "i5NQf18tajPp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q5. Which of the words **battle** and **love** are closest to the word **fight**? Explain your answer."
      ],
      "metadata": {
        "id": "XXsE97F0Fu9E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# higher score -> words closer\n",
        "sim_battle = google_news_vectors.similarity('fight', 'battle')\n",
        "sim_love = google_news_vectors.similarity('fight', 'love')\n",
        "print('similarity fight-battle : ', sim_battle)\n",
        "print('similarity fight-love : ', sim_love)"
      ],
      "metadata": {
        "id": "Jelsj_Q7bPth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q6. Explore the corpus for gender bias in science. Start by considering that Albert Einstein is probably the most famous scientist. If you detect bias, elaborate on why it may be present, with specific examples, and what steps could be taken to address such bias."
      ],
      "metadata": {
        "id": "Hl3rArnBFw1f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ref - https://arxiv.org/abs/1607.06520 - an is to Computer Programmer as Woman is to Homemaker? Debiasing Word Embeddings\n",
        "einstein_bias = google_news_vectors.most_similar(positive=['Einstein', 'woman'], negative=['man'], topn=3)\n",
        "einstein_bias"
      ],
      "metadata": {
        "id": "eBLbVv8lt-tz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q7. How is a word vector represented as a Python data structure? Explain with an example from the corpus."
      ],
      "metadata": {
        "id": "HbEe1xbuFzTD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Einstein_vector = google_news_vectors['Einstein']\n",
        "print (Einstein_vector)\n",
        "print (type(Einstein_vector))\n",
        "print (Einstein_vector.shape)"
      ],
      "metadata": {
        "id": "6gQnBycvcVkJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Q8.  Which of these words is the odd one out? **California Texas Alaska India**"
      ],
      "metadata": {
        "id": "CktD50WNF1H0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "## https://tedboy.github.io/nlps/generated/generated/gensim.models.Word2Vec.doesnt_match.html#gensim.models.Word2Vec.doesnt_match\n",
        "words = ['California','Texas','Alaska','India']\n",
        "result = google_news_vectors.doesnt_match(words)\n",
        "print (result)\n",
        "###########\n",
        "print('-'*40)\n",
        "word_pair_similarity = [(w1, w2, google_news_vectors.similarity(w1,w2)) for w1,w2 in combinations(words, 2)]\n",
        "word_pair_similarity_sorted = sorted(word_pair_similarity, key=lambda x: x[2], reverse=True)\n",
        "\n",
        "for ( w1, w2, score) in word_pair_similarity_sorted :\n",
        "    print(f\"{w1:15} {w2:15} {score}\")"
      ],
      "metadata": {
        "id": "r8k0ki7AhtCX"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4 (tags/v3.10.4:9d38120, Mar 23 2022, 23:13:41) [MSC v.1929 64 bit (AMD64)]"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "b68f8234f4664cd92394ba08fd2bcacafca488f50355ff1b3e37ec2c2f0f7027"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}